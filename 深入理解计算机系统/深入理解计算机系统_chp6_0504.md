# 深入理解计算机系统



## 第六章 存储器层次结构

![image-20230504202703039](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230504202703039.png)

**存储器系统（memorysystem）是一个具有不同容量、成本和访间时间的存储设备的层次结构。**

**简单模型：线性字节数组。**

**层次结构模型：CPU寄存器保存着最常用的数据。靠近CPU的小的、快速的高速缓存存储器（cachememory）作为一部分存储在相对慢速的主存储器（mainmemory）中数据和指令的缓冲区域。主存缓存存储在容量较大的、慢速磁盘上的数据，而这些磁盘常常又作为存储在通过网络连接的其他机器的磁盘或磁带上的数据的缓冲区域。**

### 6.1 存储技术

#### 6.1.1 随机访问储存器RAM

**随机访问存储器（Random-Access Memory，RAM）**分为两类：**静态的SRAM**和**动态的DRAM**。

- **静态RAM（SRAM）比动态RAM（DRAM）更快，但也贵得多。**
- **SRAM用来作为高速缓存存储器**，既可以在CPU芯片上，也可以在片下。
- **DRAM用来作为主存以及图形系统的植缓冲区。**典型地，一个桌面系统的SRAM不会超过几兆字节，但是DRAM却有儿百或几千兆字节。

##### 静态RAM(SRAM)

SRAM将每个位存储在一个双稳态的（bistable）存储器单元里。每个单元是用一个六晶体管电路来实现的。**每个存储单元都由两个互补的反向双稳态电路所组成，使得每个存储单元能够保持两个稳定的状态（即0和1状态）。**

SRAM的存储单元通常由六个晶体管组成：**两个访问晶体管和四个存储晶体管。**其中，两个访问晶体管用于读取和写入数据，而四个存储晶体管则组成了反向双稳态电路。

**反向双稳态电路**由两个反向的CMOS反馈环路组成，每个环路都包含了两个传输门和一个反相器。这种电路设计使得存储单元的状态可以在两个不同的电平下稳定，即在高电平和低电平下分别稳定。它可以无限期地保持在两个不同的电压配置（configuration）或状态（state）之一。其他任何状态都是不稳定的—从不稳定状态开始，电路会迅速地转移到两个稳定状态中的一个。这样一个存储器单元类似于图6-1中画出的倒转的钟摆。

![image-20230504205136141](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230504205136141.png)

**SRAM运作过程：**

**写入数据时，访问晶体管会将数据写入存储晶体管中，从而改变存储单元的状态。**

**读取数据时，访问晶体管会根据存储晶体管的状态来输出相应的数据。**

由于存储单元的状态可以在**两个不同的电平下稳定**，因此SRAM具有快速的读取速度和低功耗的特点。**（只有两个状态）**

1. 双稳态设计使得存储单元的状态可以在两个不同的电平下稳定，即在高电平和低电平下分别稳定。这使得**SRAM的读取速度非常快**，因为<u>只需要检测存储单元的电平状态即可输出相应的数据，而不需要进行任何计算或操作。</u>
2. SRAM中的存储单元采用了反向双稳态电路，这种电路具有自持续的特性，即一旦存储单元被写入数据，它就能够自行保持该状态，而不需要外部电源的维持。这使得**SRAM在存储数据时非常省电**，因为不需要持续的电源输入来维持存储单元的状态。<u>只要有电，它就会永远地保持它的值，即使有干扰（例如电子噪音）来扰乱电压，当干扰消除时，电路就会回复到稳定值。</u>
3. SRAM中的访问晶体管和存储晶体管采用了CMOS技术，这种技术具有非常低的功耗和高的噪声抗干扰能力。因此，SRAM的功耗非常低，可以满足许多低功耗应用的需求。

##### 动态RAM(DRAM)

DRAM存储器可以制造得非常密集——**每个单元由一个电容和一个访问晶体管组成。**

但是，与SRAM不同，DRAM存储器单元对干扰非常敏感。当电容的电压被扰乱之后，就会使DRAM单元在10～100毫秒时间内失去电荷，从而丢失数据。不过计算机运行的时钟周期是以纳秒来衡量的，所以相对而言这个保持时间是比较长的。

所以**内存系统必须周期性地通过读出，然后重写来刷新内存每一位——刷新操作。**有些系统也使用**纠错码**，其中计算机的字会被多编码几个位（例如64位的字可能用72位来编码），这样一来，电路可以发现并纠正一个字中任何单个的错误位。

###### SRAM&DRAM对于数据的保存

- 当断电之后，SRAM中的数据无法保留，因为它的存储单元采用的是双稳态设计，需要持续的电源输入来维持存储单元的状态。一旦断电，存储单元中的电荷就会逐渐泄漏，最终导致数据丢失。
- DRAM中的存储单元采用的是电容存储器，可以在一定时间内保持电荷，即使断电后也能够通过刷新操作来维持存储单元中的数据。因此，DRAM在断电后可以通过**刷新**操作来恢复存储的数据，而SRAM则无法实现该功能。需要注意的是，**即使是在DRAM中，如果断电时间过长或者刷新操作不及时，也会导致存储单元中的数据丢失。**因此，在使用任何类型的内存芯片时，都需要注意及时备份数据并采取适当的措施来防止数据丢失。

###### 对比&总结

|      | 每位晶体管数 | 相对访问时间 | 持续的？ | 敏感的？ | 相对花费 | 应用           |
| ---- | ------------ | ------------ | -------- | -------- | -------- | -------------- |
| SRAM | 6            | 1*           | 是       | 否       | 1000*    | 高速缓存存储器 |
| DRAM | 1            | 10*          | 否       | 是       | 1*       | 主存，帧缓冲区 |

**SRAM中6个晶体管成本更高，只有两个电平状态，可以快速读取数据，访问速度更快，不过需要持续电源保持数据。DRAM中1个电容1个晶体管成本低，但是电容存储结构复杂，而且易被干扰需要不断刷新保持数据，所以访问速度较低。**

###### 补充：帧缓冲区

**帧缓冲区（Frame Buffer）**是计算机图形学中的一个概念，它是用于存储图像或视频帧的一块内存区域。帧缓冲区通常被用于显示器、投影仪等显示设备中，用于存储待显示的图像或视频帧，以便于显示设备能够将其显示出来。

在使用帧缓冲区时，计算机会将待显示的图像或视频帧存储在内存中，然后将帧缓冲区中的数据通过显示设备的控制器输出到屏幕上。由于帧缓冲区中存储的是完整的图像或视频帧数据，因此可以实现全屏幕的高分辨率显示，而不需要频繁地进行屏幕刷新操作。

帧缓冲区的大小通常与显示设备的分辨率和色深有关，较高分辨率和色深的显示设备通常需要更大的帧缓冲区。在实际应用中，帧缓冲区的大小也会受到计算机硬件性能和内存容量的限制。

##### 传统的DRAM

DRAM芯片中的单元（位）被分成d个**超单元**（supercell），每个超单元都由个DRAM单元组成。一个`d*w`的DRAM总共存储了`dw`位信息。

超单元被组织成一个r行c列的长方形阵列，这里`rc=d`。每个超单元有形如`(i，j)`的地址，这里i表示行，而j表示列。

例如，图6-3展示的是一个16×8的DRAM芯片的组织，有d=16个超单元，每个超单元有z=8位，r=4行，c=4列。带阴影的方框表示地址（2，1）处的超单元。信息通过称为引脚（pin）的外部连接器流人和流出芯片。每个引脚携带一个1位的信号。图6-3给出了两组引脚：8个`data`引脚，它们能传送一个字节到芯片或从芯片传出一个字节，以及2个`addr`引脚，它们携带2位的行和列超单元地址。其他携带控制信息的引脚没有显示出来。

**引脚**是指电子器件或电路中的连接点，用于连接其他电子器件或电路。在集成电路中，引脚通常被用来连接芯片内部的电路和外部的电路。

![image-20230507140615270](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230507140615270.png)

##### 内存模块

DRAM芯片封装在**内存模块（memorymodule）**中，它插到主板的扩展槽上。Corei7系统使用的240个引脚的双列直插内存模块，它以64位为块传送数据到内存控制器和从内存控制器传出数据。

图6-5展示了一个内存模块的基本思想。

**内存模块----内存芯片----超单元**

示例模块用8个64Mbit的8M*8的DRAM芯片，总共存储64MB（兆字节），这8个芯片编号为0～7。每个超单元存储主存的一个字节，而用相应超单元地址为（i，j）的8个超单元来表示主存中字节地址A处的64位字。在图6-5的示例中，DRAM0存储第一个（低位）字节，DRAM1存储下一个字节，依此类推。

要取出内存地址A处的一个字，内存控制器将A转换成一个超单元地址（i，j），并将它发送到内存模块，然后内存模块再将i和j广播到每个DRAM。作为响应，每个DRAM输出它的（i，j）超单元的8位内容。模块中的电路收集这些输出，并把它们合并成一个64位字，再返回给内存控制器。

**通过将多个内存模块连接到内存控制器，能够聚合成主存。**在这种情况中，当控制器收到一个地址A时，控制器选择包含A的模块k，将A转换成它的（i，j）的形式，并将（i，j）发送到模块k。

![image-20230507141715236](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230507141715236.png)

##### 增强的DRAM

- **快页模式DRAM(FPM DRAM)**

传统的DRAM将超单元的一整行复制到它的内部行缓冲区中，使用一个，然后丢弃剩余的。FPMDRAM允许**对同一行连续地访问可以直接从行缓冲区得到服务**，从而改进了这一点。

例如，要从一个传统的DRAM的行i中读4个超单元，内存控制器必须发送4个RAS/CAS请求，即使是行地址在每个情况中都是一样的。要从一个FPMDRAM的同一行中读取超单元，内存控制器发送第一个RAS/CAS请求，后面跟三个CAS请求。初始的RAS/CAS请求将行i复制到行缓冲区，并返回CAS寻址的那个超单元。接下来三个超单元直接从行缓冲区获得，因此返回得比初始的超单元更快。

- **扩展数据输出DRAM(EDO DRAM)**

FPMDRAM的一个增强的形式，它允许**各个CAS信号在时间上靠得更紧密一点**。

- **同步DRAM(SD RAM)**

就它们与内存控制器通信使用一组显式的控制信号来说，常规的、FPM和EDODRAM都是异步的。

SDRAM用与驱动内存控制器相同的外部时钟信号的上升沿来代替许多这样的控制信号。效果就是S**DRAM能够比那些异步的存储器更快地输出它的超单元的内容**。

- **双倍数据速率同步DRAM(DDR SDRAM)**

DDRSDRAM是对SDRAM的一种增强，**它通过使用两个时钟沿作为控制信号，从而使DRAM的速度翻倍**。不同类型DDRSDRAM是用提高有效带宽的很小的预取缓冲区的大小来划分的：DDR（2位）、DDR2（4位）和DDR（8位）。

- **视频RAM(VRAM)**

用于图形系统的帧缓冲区中，与FPMDRAM类似。两个主要区别是：1）VRAM的输出是通过依次对内部缓冲区的整个内容进行移位得到的；2）VRAM允许对内存并行地读和写。因此，**系统**
**可以在写下一次更新的新值（写）的同时，用帧缓冲区中的像素刷屏幕（读）。**

##### 非易失性储存器

SRAM和DRAM都是易失性储存器，断电后丢失信息。非易失性储存器，例如ROM(Read-Only Memory),只读储存器。ROM是以它们能够被重编程（写）的次数和对它们进行重编程所用的机制来区分。

- 可编程ROM(PROM)，只能被编程一次。
- 可擦可编程ROM(EPROM),口，允许光到达存储单元。**EPROM能够被擦除和重编程的次数的数量级可以达到1000次。**电子可擦PROM不需要一个物理上独立的编程设备，因此可以直接在印制电路卡上编程。EEPROM能够被编程的次数的数量级可以达到10^5次。
- 闪存，基于EEPROM,重要的存储技术，为大量的电子设备提供快速而持久的非易失性存储。eg：固态硬盘SSD。

存储在ROM设备中的程序通常被称为图件（firmware）。当一个计算机系统通电以后，它会运行存储在ROM中的固件。一些系统在固件中提供了少量基本的输人和输出函数——例如PC的BIOS（基本输入/输出系统）例程。

##### 访问主存

数据传输流——**总线系统**。总线事务：读事务，数据从主存到CPU；写事务，数据从CPU到主存。

**总线是一组并行的导线，能携带地址、数据和控制信号。**取决于总线的设计，数据和
地址信号可以共享同一组导线，也可以使用不同的。同时，两个以上的设备也能共享同一总线。控制线携带的信号会同步事务，并标识出当前正在被执行的事务的类型。

![image-20230507150129660](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230507150129660.png)

```C++
movq A,RAX	//将A的值存储到寄存器RAX中

"movq"是指令的操作码，表示将一个64位的数值从一个源操作数复制到目的操作数。"A"和"RAX"是操作数，A表示一个内存地址或立即数，而RAX表示一个64位通用寄存器。因此，"movq A, rax"将A中的值复制到寄存器RAX中。
    
在执行这条指令时，如果A是一个内存地址，则处理器会将内存地址所对应的值加载到一个临时寄存器中，然后将这个临时寄存器中的值复制到RAX寄存器中。如果A是一个立即数，则处理器直接将这个立即数值复制到RAX寄存器中。
    
需要注意的是，"movq"指令的第一个操作数必须是64位的，因为它是一个64位指令。如果源操作数不足64位，则必须使用扩展或截断指令来补齐或缩短操作数，以确保指令的正确执行。
    
movq %rax,A	//将寄存器RAX的值存储到内存地址A中
    
"movq"仍然是指令的操作码，表示将一个64位的数值从一个源操作数复制到目的操作数，"%rax"表示一个64位通用寄存器，而"A"表示一个内存地址。因此，“movq %rax, A”将RAX寄存器中的值复制到内存地址A所对应的内存单元中。

在执行这条指令时，处理器会先将RAX寄存器中的值加载到一个临时寄存器中，然后将这个临时寄存器中的值存储到内存地址A对应的内存单元中。需要注意的是，A必须是一个64位内存地址，否则这条指令将无法正确地执行。如果内存地址A是一个符号地址，则需要将其转换为真实地址以防止出现内存地址错误。

这条指令在汇编语言编程中经常使用，例如在函数调用过程中将返回值存储到指定的内存地址中。因此理解如何正确地使用"movq %rax, A"指令及其与"movq A, %rax"指令之间的差异非常重要。
```

- 总线接口发起读事务,执行**`movq A,RAX`**

  首先，CPU将A的地址放到总线上，I/O桥将此信号传递到内存总线。接下来，主存从内存总线中读地址，从DRAM中取出数据字并将数据写到内存总线。I/O桥将内存总线信号翻译成系统总线信号，然后由系统总线传递数据信号。最后，CPU从总线上读取从主存中传递过来的数据并复制到寄存器`%rax`中。

<img src="https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230507150821500.png" alt="image-20230507150821500" style="zoom:67%;" />

- CPU发起写事务，执行**`movq %rax,A`**

  寄存器`%rax`的内容被写到地址A，CPU发起**写事务**。

  首先CPU将地址放到系统总线上，内存从内从总线读出地址并等待数据到达。接下来，CPU将`%rax`中的数据字复制到系统总线。最后，主存从内存总线读出数据字，并且将这些位储存到DRAM中。

  <img src="https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230507151500362.png" alt="image-20230507151500362" style="zoom:67%;" />

#### 6.1.2 磁盘储存

磁盘存储数据的数量级可以达到几百到几千千兆字节，而基于RAM的存储器只能有几百或几千兆字节。不过，从磁盘上读信息的时间为毫秒级，**比从DRAM读慢了10万倍，比从SRAM读慢了100万倍。**

##### 磁盘构造

- **磁盘(disk)**由盘片构成，每个**盘片**由两面(表面)组成，**表面**覆盖着磁性记录材料。
- 磁盘通常包含一个或者多个盘片，封装在一个密闭容器中。
- 盘片中央有一个可旋转的**主轴**，使盘片以固定速率旋转，通常是5400～15000转每分钟。
- 每个表面由一组称为**磁道(track)**的同心圆组成。
- 每个磁道被划分为一组**扇区(sector)**，每个扇区包含相等数量的数据位(通常为512字节)，这些数据为在扇区上的磁性材料中。
- 扇区之间由一些**间隙(gap)**分隔开，gap中不储存数据位，储存用来标识扇区的格式化位。

![image-20230507155535951](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230507155535951.png)

- **柱面(cylinder)**是所有盘片表面上到主轴中心的距离相等的磁道的集合

##### 磁盘容量

- **记录密度（recordingdensity）**（位/英寸）：磁道一英寸的段中可以放人的位数。
- **磁道密度（trackdensity）（**道/英寸）：从盘片中心出发半径上一英寸的段内可以有的磁道数。
- **面密度（arealdensity）**（位/平方英寸）：记录密度与磁道密度的乘积。

磁盘制造厂商通过不断**提高面密度从而增加磁盘容量**。随着面密度的提高，扇区之间的间隙变得不可接受地大(此区域并不储存数据)。因此现代磁盘使用**多区记录技术**，通过划分扇区分割柱面。

- **计算磁盘容量**

  ![image-20230507161936568](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230507161936568.png)

```c++
补充：一千兆字节
对于DRAM&SRAM：K=2^10,M=2^20,G=2^30,T=2^40
对于磁盘和网络这样的I/O设备：K=10^3,M=110^6,G=10^9,T=10^12
```

##### 磁盘操作

**磁盘用读/写头（read/writehead）来读写存储在磁性表面的位，而读写头连接到一个传动臂（actuatorarm）一端**，如图6-10a所示。通过沿着半径轴前后移动这个传动臂，驱动器可以将读/写头定位在盘面上的任何磁道上。这样的机械运动称为寻道（seek）。一旦读/写头定位到了期望的磁道上，那么当磁道上的每个位通过它的下面时，读/写头可以感知到这个位的值（读该位），也可以修改这个位的值（写该位）。有多个盘片的磁盘针对每个盘面都有一个独立的读/写头，如图6-10b所示。读/写头垂直排列，一致行动速度大约为80km/h。**在任何时刻，所有的读/写头都位于同一个柱面上。**

![image-20230507164019090](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230507164019090.png)

- **寻道时间(传动臂定位磁道)**

  **为了读取某个目标扇区的内容，传动臂首先将读/写头定位到包含目标扇区的磁道上所需的时间。**现代驱动器中平均寻道时间通常为3～9ms。一次寻道的最大时间可以高达20ms。

- **旋转时间(驱动器定位目标扇区起始位置)**

  驱动器等待目标扇区的第一个位旋转到读/写头下。这个步骤的性能依赖于当读/写头到达目标扇区时盘面的位置以及磁盘的旋转速度。在最环的情况下，读/写头刚刚错过了目标扇区，必须等待磁盘转一整圈。

- **传送时间(读写数据)**

  当目标扇区的第一个位位于读/写头下时，驱动器就可以开始读或者写该扇区的内容了。**一个扇区的传送时间依赖于旋转速度和每条磁道的扇区数目。**

![image-20230508111746230](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230508111746230.png)

- 访间一个磁盘扇区中512个字节的时间主要是寻道时间和旋转延迟。访问扇区中的
  第一个字节用了很长时间，但是访问剩下的字节几乎不用时间。
- 因为寻道时间和旋转延退大致相等，所以将寻道时间乘2是估计磁盘访问时间的简
  单而合理的方法。
- 对存储在SRAM中的一个64位字的访问时间大约是4ns，对DRAM的访问时间是
  60ns。因此，从内存中读一个512个字节扇区大小的块的时间对SRAM来说大约是
  256ns，对DRAM来说大约是4000ns。磁盘访问时间，大约10ms，是SRAM的大
  约40000倍，是DRAM的大约2500倍。

##### 逻辑磁盘块(抽象)

现代磁盘构造复杂，为了对操作系统隐藏这样的复杂性，现代磁盘将它们的构造呈现为一个简单的视图。

针对一个B个扇区大小的逻辑决的序列，编号为0，1，…，B-1。磁盘封装中有一个小的硬件/固件设备，称为**磁盘控制器**，维护着**逻辑块号**和**实际（物理）磁盘扇区**之间的映射关系。

**操作系统要独一个磁盘扇区地数据到主存**

- 操作系统会发送一个命令到磁盘控制器，让它读某个**逻辑块号**。
- 控制器上的固件执行一个快速表查找，**将一个逻辑块号翻译成一个（盘面，磁道，扇区）的三元组**，这个三元组唯一地标识了对应的物理扇区。
- **控制器上的硬件会解释这个三元组**，将读/写头移动到适当的柱面，等待扇区移动到读/写头下，将读/写头感知到的位放到控制器上的一个小缓冲区中，然后将它们复制到主存中。

```c++
补充：
磁盘控制器必须对磁盘进行格式化，然后才能在该磁盘上存储数据。
格式化包括用标识扇区的信息填写扇区之间的间隙，标识出表面有故障的柱面并且不使用它们，以及在每个区中预留出一组柱面作为备用，如果区中一个或多个柱面在磁盘使用过程中坏掉了，就可以使用这些备用的柱面。
因为存在着这些备用的柱面，所以磁盘制造商所说的格式化容量比最大容量要小。
```

##### 连接I/O设备(I/O总线)

虽然I/O总线比系统总线和内存总线慢，但是它可以容纳种类繁多的第三方I/O设备。

<img src="https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230508112956364.png" alt="image-20230508112956364" style="zoom:80%;" />

- **通用串行总线(USB)控制器**是一个连接到USB总线地设备地中转处，USB总线是一个广泛使用的标准，连接各种外围I/O设备。USB3.0总线的最大带宽为625MB/s。USB3.1总线的最大带宽为1250MB/s。
- **图形卡（或适配器）**包含硬件和软件逻辑，它们负责代表CPU在显示器上画像素。
- **主机总线适配器**将一个或多个磁盘连接到I/O总线，使用的是一个特别的主机总线接口定义的通信协议。两个最常用的这样的磁盘接口是**SCSI**和**SATA**。SCSI磁盘通常比SATA驱动器更快但是也更贵。SCSI主机总线适配器（通常称为SCSI控制器）可以支持多个磁盘驱动器，与SATA适配器不同，它只能支持一个驱动器。

##### 访问磁盘 

CPU使用一种称为**内存映射I/O**（memory-mapped I/O）的技术来向I/O设备发射命令
（图6-12a）。在使用内存映射I/O的系统中，**地址空间中有一块地址是为与I/O设备通信保留的。**每个这样的地址称为一个I/O端口（I/O port）。当一个设备连接到总线时，它与一个或多个端口相关联（或它被映射到一个或多个端口）。

![image-20230508114136709](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230508114136709.png)

**磁盘读过程举例**：

假设磁盘控制器映射到端口0xa0。**第一条**指令是发送一个命令字，告诉磁盘发起一个读，同时还发送了其他的参数，例如当读完成时，是否中断CPU。**第二条**指令指明应该读的**逻辑块号**。**第三条**指令指明应该存储磁盘扇区内容的主存地址。

**干什么(读操作)，目标(逻辑块号)，处理空间(储存指令的主存地址)**

##### 直接内存访问(DMA)

- **所优化的的问题**

当CPU发出了请求之后，在磁盘执行读的时候，CPU什么也不做只是等待。一个1GHz的处理器时钟周期为1ns，在用来读磁盘的16ms时间里，它潜在地可能执行1600万条指令。**DMA过程则不要CPU的干涉，直接解放CPU，减少其负担。**

- **DMA过程**

具体来说，当外设需要读取或写入数据时，DMA控制器会向CPU发出请求，请求CPU将外设需要访问的数据的内存地址和数据长度存储到DMA控制器的寄存器中。然后，DMA控制器会直接访问内存，将数据传输到或从外设中读取数据。传输完成后，DMA控制器会向CPU发出中断请求，通知CPU传输已经完成，CPU可以继续执行其他任务。

- **DMA的实现**

通过特殊的硬件技术，提高制造成本从而提高效率。

DMA的实现方式通常是通过硬件实现的。具体来说，DMA控制器通常包括**一个DMA引擎和一组DMA通道**。当外设需要读取或写入数据时，DMA控制器会向CPU发出请求，请求CPU将外设需要访问的数据的内存地址和数据长度存储到DMA控制器的寄存器中。然后，DMA引擎会直接访问内存，将数据传输到或从外设中读取数据。**传输完成后，DMA控制器会向CPU发出中断请求，通知CPU传输已经完成，CPU可以继续执行其他任务。**

#### 6.1.3 固态硬盘

固态硬盘(SSD)是一种基于闪存的储存技术。封装插到I/O总线上标准硬盘插槽（通常是USB或SATA）中，处理来自CPU的读写逻辑磁盘块的请求。**一个SSD封装由一个或多个闪存芯片和闪存翻译层（flashtranslationlayer）组成**，**闪存芯片**替代传统旋转磁盘中的机械驱动器，而**闪存翻译层**是一个硬件/固件设备，扮演与磁盘控制器相同的角色，将对逻辑块的请求翻译成对底层物理设备的访问。

![image-20230510192842519](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230510192842519.png)

SSD的读要比写快，随机读和写的性能差别由底层闪存基本属性决定。

##### 补充：闪存

闪存的技术原理是基于电荷存储原理和半导体工艺实现的。闪存内部由许多小型的存储单元组成，每个存储单元都可以存储一个二进制位（0或1）。这些存储单元被排列成一个二维的矩阵，每个单元都有一个独特的地址，可以通过该地址读取或写入数据。

在闪存中，每个存储单元都有一个控制门和一个浮动栅，控制门用于控制数据的读取和写入，而浮动栅则用于存储电荷。当数据被写入闪存时，电荷被注入到浮动栅中，这会改变其电荷状态，从而表示存储的数据。当需要读取数据时，控制门会打开，允许电荷流经存储单元，从而读取存储的数据。

闪存的实现方法主要有两种：NAND闪存和NOR闪存。NAND闪存是一种串行存储器，它将数据存储在一系列的存储单元中，并通过多路复用器将数据读取出来。NOR闪存则是一种并行存储器，它将数据存储在一组并行的存储单元中，并通过地址线直接访问数据。

在实际应用中，闪存通常与控制器一起使用，控制器负责管理闪存的读写操作，并提供接口供CPU和其他设备访问。闪存还可以通过各种接口进行连接，如SATA、PCIe、USB等，以便于与其他设备进行通信和数据交换。

##### SSD的组成原理

一个闪存由B个块的序列组成，每个块由P页组成。页的大小是512字节～4KB，块是由32～128页组成的，块的大小为16KB～512KB。数据是以页为单位读写的。**只有在一页所属的块整个被擦除之后，才能写这一页（通常是指该块中的所有位都被设置为1）**。不过，一**旦一个块被擦除了，块中每一个页都可以不需要再进行擦除就写一次。**在大约进行100000次重复写之后，块就会磨损坏。一旦一个块磨损坏之后，就不能再使用了。

随机写很慢，有两个原因。首先，擦除块需要相对较长的时间，1ms级的，比访问页所需时间要高一个数量级。其次，如果写操作试图修改一个包含已经有数据（也就是不是全为1）的页，那么这个块中所有带有用数据的页都必须被复制到一个新（擦除过的）块，然后才能进行对页的写。制造商已经在闪存翻译层中实现了复杂的逻辑，试图抵消擦写块的高昂代价，最小化内部写的次数，但是随机写的性能不太可能和读一样好。

##### **比起旋转磁盘，SSD有很多优点**

它们由半导体存储器构成，没有移动的部件，因而随机访问时间比旋转磁盘要快，能耗更低，同时也更结实。不过，也有一些缺点。首先，因为反复写之后，闪存块会磨损，所以SSD也容易磨损。闪存翻译层中的平均磨损（wearleveling）逻辑试图通过将擦除平均分布在所有的块上来最大化每个块的寿命。实际上，平均磨损逻辑处理得非常好，要很多年SSD才会磨损坏。其次，SSD每字节比旋转磁盘贵大约30倍，因此常用的存储容量比旋转磁盘小100倍。

#### 6.1.4 存储技术趋势

不同的存储技术有不同的价格和性能折中。**SRAM比DRAM快一点，而DRAM比磁盘要快很多。另一方面，快速存储总是比慢速存储要贵的。SRAM每字节的造价比DRAM高，DRAM的造价又比磁盘高得多。SSD位于DRAM和旋转磁盘之间。**

![image-20230510203420144](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230510203420144.png)

### 6.2 局部性

**局部性原理**：一个编写良好的计算机常常具有良好的**局部性**，它们倾向于引用临近于其他最近引用过的数据项的数据项，或者最近引用过的数据项本身。

局部性通常有两种形式：**时间局部性**和**空间局部性**。在一个**具有良好时间局部性**的程序中，被引用过一次的内存位置很可能在不远的将来再被**多次引用**。在一个**具有良好空间局部性**的程序中，如果一个内存位置被引用了一次，那么程序很可能在不远的将来引用附近的一个内存位置。

**提高效率，节省空间。**（输入法中的偏好记录？）

硬件层：利用**高速缓存储存**来保存最近被引用过的指令和数据项，从而提高对主存的访问速度。

操作系统：允许系统**使用主存作为虚拟地址空间**最近被引用块的高速缓存。用主存来缓存磁盘文件中最近被使用的磁盘块。

Web浏览器：将最近被引用的文档放在本地磁盘上。

#### 6.2.1 对程序数据引用的局部性

##### 求一个向量的元素之和的函数

```c++
//求一个向量的元素之和
int sumvec(int v[N])
{
	int i,sum=0;
    
    for(i=0;i<N;i++)
        sum+=v[i];
    
    return sum;
}
```

向量v的引用模式(N=8):

| **地址**     | 0    | 4    | 8    | 12   | 16   | 20   | 24   | 28   |
| ------------ | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| **内容**     | v0   | v1   | v2   | v3   | v4   | v5   | v6   | v7   |
| **访问顺序** | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    |

**步长为1的顺序引用模式**

此函数具有**很好的空间局部性**，这个函数具有很好的空间局部性，因为<u>它连续地访问了数组v中的元素，这些元素在内存中是相邻存储的，因此当CPU加载第一个元素时，它会预加载相邻的元素到CPU缓存中，以便在循环中快速访问它们，从而提高程序的执行效率</u>。这种连续的内存访问方式可以充分利用CPU缓存，减少了访问内存的次数，从而提高了程序的性能。

此函数的**时间局部性较差**，因为它<u>每次循环都要重新访问数组v中的元素</u>，而不是利用之前已经加载到CPU缓存中的元素。这会导致CPU缓存中的数据被频繁地替换，从而降低了程序的执行效率。如果数组v的大小很大，而CPU缓存的大小有限，那么程序的性能将会受到更大的影响。为了提高程序的时间局部性，可以考虑使用循环展开、向量化等技术，以减少循环次数和提高CPU的指令级并行度。

##### 求一个二维数组的元素之和

```c++
//双重嵌套循环按照行优先顺序读数组的元素
//空间局部性好
int sumarrayrows(int a[m][n])
{
    int i,j,sum=0;
    
    for(i=0;i<m;i++)
    {
		for(j=0;j<n;j++){
            sum+=a[i][j];
        }
    }
    return sum;
}
//假设有一个二维数组A，它有m行n列，代码按行优先的方式访问A中的元素，那么访问A[i][j]时，程序会首先访问A[i][0]、A[i][1]、A[i][2]、...、A[i][n-1]，然后再访问A[i+1][0]、A[i+1][1]、A[i+1][2]、...、A[i+1][n-1]，以此类推，直到访问完所有元素。

//修改成按照列优先顺序读数组元素
//空间局部性差
int sumarraycols(int a[m][n])
{
    int i,j,sum=0;
    
    for(j=0;j<n;j++)//循环调换索引i和j的内外位置
    {
		for(i=0;i<m;i++){
            sum+=a[i][j];
        }
    }
    return sum;
}
```

数组a的引用模式(m=2,n=3)

| 地址     | 0    | 4    | 8    | 12   | 16   | 20   |
| -------- | ---- | ---- | ---- | ---- | ---- | ---- |
| 内容     | a00  | a01  | a02  | a10  | a11  | a12  |
| 访问顺序 | 1    | 2    | 3    | 4    | 5    | 6    |

**按行优先读取二维数组可以改进程序的空间局部性，因为这样可以利用CPU缓存的行缓存机制。当程序按行访问数组时，CPU缓存会缓存一整行的数据，这样在访问下一个元素时，该元素就已经在CPU缓存中了，可以直接访问，不需要再次从内存中读取，从而加快了程序的执行速度。而按列优先读取二维数组时，CPU缓存只能缓存一列的数据，这样在访问下一个元素时，需要从内存中读取一整列的数据，这样会导致CPU缓存中的数据被频繁地替换，从而降低了程序的执行效率。**

##### 补充：行缓存机制

**CPU的行缓存机制是一种常见的缓存优化技术，它可以提高程序的执行效率。**

**行缓存是指CPU缓存中缓存的是内存中的一整行数据，而不是单个字节或单个字。**这样做的好处是，当CPU需要访问内存中的一个字节或一个字时，它可以将整行数据加载到缓存中，以便将来访问相邻的字节或字时可以直接从缓存中读取，而不需要再次访问内存。

行缓存机制的**实现方式**是，当CPU需要访问内存中的一个字节或一个字时，它会将整个缓存行加载到缓存中。如果CPU需要访问相邻的字节或字，它可以直接从缓存中读取，而不需要再次访问内存。这样可以大大减少内存访问的次数，从而提高程序的执行效率。

另外，行缓存机制还可以通过**预取技术**来进一步提高程序的执行效率。预取是指CPU在访问一个缓存行时，预先将相邻的缓存行加载到缓存中，以便将来访问相邻的缓存行时可以直接从缓存中读取，而不需要再次访问内存。这样可以进一步减少内存访问的次数，从而提高程序的执行效率。

需要注意的是，行缓存机制并不是完美的，它有一些**缺点**。首先，如果程序访问的数据不是按行排列的，那么行缓存机制就无法充分发挥作用。其次，如果程序访问的数据是**随机的**，那么行缓存机制也无法发挥作用。因此，在实际应用中，需要根据具体情况选择合适的缓存优化技术。

实际上，现代CPU中的缓存系统并不是只有行缓存机制，还有一些其他的缓存机制，例如**组相联缓存、多级缓存、预取缓存**等。但是，列缓存机制并不是常见的缓存优化技术。

这是因为，在计算机科学中，**数组通常是按行存储的，而不是按列存储的。**这是因为按行存储可以充分利用CPU缓存的行缓存机制，从而提高程序的执行效率。相反，**如果数组按列存储，那么CPU缓存中的数据就会被频繁地替换，从而降低程序的执行效率。**

另外，列缓存机制的实现也比较复杂。因为在列缓存中，缓存行必须包含整个列，而不是整个行。这意味着每个缓存行的大小可能会非常大，导致缓存容量的浪费。此外，由于缓存行的大小不是固定的，这也会导致缓存管理的复杂性增加。

因此，虽然列缓存机制在某些特定的应用场景中可能会有一定的优势，但是在大多数情况下，行缓存机制仍然是更为常见和有效的缓存优化技术。

##### 练习

**步长为1的顺序引用模式**

```
//改变下面函数中循环的顺序，使得它以步长为1的引用模式扫描三维数组a
int sumarray3d(int a[n][n][n])
{
    int i,j,k,sum=0;
    
    for(i=0;i<m;i++){
    	for(j=0;j<n;j++){
    		for(k=0;k<n;k++){
           		sum+=a[k][i][j];}
        }
    }
    return sum;
}

int sumarrayrows1(int a[n][n][n])
{
    int i,j,k,sum=0;
    
    for(k=0;k<n;k++){
        for(i=0;i<m;i++){
            for(j=0;j<n;j++){
                sum+=a[k][i][j];
            }
        }
    }
    return sum;
}

```

**结构体**

```c++

#define N 1000

typedef struct{
    int vel[3];
    int acc[3];
}

point p[N];

void clear1(point *p,int n){
    int i,j;
    for(i=0;i<3;i++){
        p[i].vel[j]=0;
    }
    for(j=0;j<3;j++){
        p[i].acc[j]=0;
    }
}

void clear2(point *p,int n){
	int i,j;
    for(i=0;i<3;i++){
        for(j=0;j<3;j++){
        	p[i].vel[j]=0;
        	p[i].acc[j]=0;
        }
    }
}

void clear3(point *p,int n){
	int i,j;
    for(j=0;j<3;j++){
        for(i=0;i<3;i++){
        	p[i].vel[j]=0;
        }
        for(i=0;i<3;i++){
            p[i].acc[j]=0;
        }
    }
}
```

解决这个间题的关键在于想象出数组是如何在内存中排列的，然后分析引用模式。

函数`clear1`以步长为1的引用模式访问数组，因此明显地具有最好的空间局部性。函数`clear2`依次扫描N个结构中的每一个，这是好的，但是在每个结构中，它以步长不为1的模式跳到下列相对于结构起始位置的偏移处：0、12、4、16、8、20。所以`clear2`的空间局部性比`clear1`的要差。函数`clear3`不仅在每个结构中跳来跳去，而且还从结构跳到结构，所以`clear3`的空间局部性比`clear2`和`clear1`都要差。

#### 6.2.2 取指令的局部性

因为程序指令是存放在内存中的，CPU必须取出（读出）这些指令，所以我们也能够评价一个程序关于取指令的局部性。例如，图6-17中for循环体里的指令是按照连续的内存顺序执行的，因此循环有良好的空间局部性。因为循环体会被执行多次，所以它也有很好的时间局部性。

代码区别于程序数据的一个重要属性是在运行时它是不能被修改的。当程序正在执行
时，CPU只从内存中读出它的指令。CPU很少会重写或修改这些指令。

#### 6.2.3 局部性小结

- **重复引用相同变量的程序有良好的时间局部性。**
- **对于具有步长为k的引用模式的程序，步长越小，空间局部性越好。具有步长为1的引用模式的程序有很好的空间局部性。在内存中以大步长跳来跳去的程序空间局部性会很差。**
- **对于取指令来说，循环有好的时间和空间局部性。循环体越小，循环选代次数越多，局部性越好。**

### 6.3 存储器层次结构

- 存储技术：不同存储技术的访问时间差异很大。速度较快的技术每字节的成本要比速度较慢的技术高，而且容量较小。CPU和主存之间的速度差距在增大。
- 计算机软件：一个编写良好的程序倾向于展示出良好的局部性。

![image-20230511202933425](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230511202933425.png)

#### 6.3.1 存储器层次结构中的缓存

**高速缓存(cache)**是一个小而快的存储设备，它作为存储在更大、更慢的设备中的数据对象的缓冲区域。使用高速缓存的过程被称为**缓存(caching)**。

图6-22展示了**存储器层次结构中缓存**的一般性概念。第k+1层的存储器被划分成连续的数据对象组块（chunk），称为块（block）。每个块都有一个唯一的地址或名字，使之区别于其他的块。块可以是固定大小的（通常是这样的），也可以是可变大小（例如存储在Web服务器上的远程HTML文件）。例如，图6-22中第k+1层存储器被划分成16个大小固定的块，编号为0～15。

**对于每个k，位于k层的更快更小的存储设备作为位于k+1层的更大更慢的存储设备的缓存。换句话说，层次结构中的每一层都缓存来自较低一层。**

**在任何时刻，第k层的缓存包含第k+1层块的一个子集的副本。**

![image-20230515104934655](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230515104934655.png)

**数据总是以块大小为传送单元（transferunit）在第层和第k+1层之间来回复制的。虽然在层次结构中任何一对相邻的层次之间块大小是固定的，但是其他的层次对之间可以有不同的块大小。**

##### 缓存命中

当程序需要第k+1层的某个数据对象d时，它首先在当前存储在第k层的一个块中查找d。如果d刚好缓存在第k层中，那么就是我们所说的**缓存命中**（cachehit）。该程序
直接从第k层读取d，根据存储器层次结构的性质，这要比从第k+1层读取d更快。例如，一个有良好时间局部性的程序可以从块14中读出一个数据对象，得到一个对第k层的缓存命中。

**第k层成功缓存所需要的第k+1层的数据。**

##### 缓存不命中

如果第层中没有缓存数据对象d，那么就是我们所说的**缓存不命中**。当发生缓存不命中时，第k层的缓存从第k+1层缓存中取出包含d的那个块，如果第k层的缓存已经满了，可能就会覆盖现存的一个块。

覆盖一个现存的块的过程称为替换（replacing）或驱逐（evicting）这个块。被驱逐的这个块有时也称为**牺牲块**（victim block）。决定该替换哪个块是由缓存的替换策略（replacementpolicy）来控制的。例如，一个具有**随机替换策略**的缓存会随机选择一个牺牲块。一个具有**最近最少被使用（LRU）替换策略**的缓存会选择那个最后被访问的时间距现在最远的块。

在第k层缓存从第k+1层取出那个块之后，程序就能像前面一样从第k层读出d了。例如，在图6-22中，在第层中读块12中的一个数据对象，会导致一个缓存不命中，因
为块12当前不在第k层缓存中。一旦把块12从第k+1层复制到第k层之后，它就会保
持在那里，等待稍后的访问。

##### 缓存不命中的种类

一个空的缓存被称为**冷缓存**(第k层的缓存中没有任何块数据)——强制性不命中/冷不命中。冷不命中为短暂事件，不会再反复访问存储器是的缓存暖身之后的稳定状态中出现。

**放置策略**：发生不命中时，则需要从第k+1层中取出目标块放置(缓存)到第k层中**。随机替换策略**是最灵活的放置策略，允许来自第k+1层的任何块放置到第k层的任何快中，但是对于较高层缓存来说通过硬件实现成本很高。

硬件缓存通常使用更严格的放置策略，存在一个确定的限制缓存位置的算法。**eg：确定第k+1层的块i必须放置在第k层的块（i mod 4）中。**这种通过模运算的放置策略(缓存算法)会引起一种不命中——**冲突不命中**。冲突不命中时，通过放置策略所确定的缓存位置可能会重复(类比哈希策略)，这些对象(目标块)被映射到同一个缓存块。eg：在图6-22中，如果程序请求块0，然后块8，然后块0，然后块8，依此类推，在第层的缓存中，对这两个块的每次引用都会不命中，即使这个缓存总共可以容纳4个块。

当工作集的大小超过缓存的大小时，缓存会经历**容量不命中**（capacitymiss）。换句话说就是，缓存太小了，不能处理这个工作集。

##### 缓存管理

管理缓存的逻辑可以是硬件、软件、或者时两者的结合。它需要把缓存划分成块，在不同的层之间传送块，判定是命中还是不命中，并处理它们

例如，编译器管理寄存器文件，缓存层次结构的最高层。它决定当发生不命中时何时
发射加载，以及确定哪个寄存器来存放数据。L1、L2和L3层的缓存完全是由内置在缓存中的硬件逻辑来管理的。在一个有虚拟内存的系统中，DRAM主存作为存储在磁盘上的数据块的缓存，是由操作系统软件和CPU上的地址翻译硬件共同管理的。对于一个具有像AFS这样的分布式文件系统的机器来说，本地磁盘作为缓存，它是由运行在本地机器上的AFS客户端进程管理的。在大多数时候，缓存都是自动运行的，不需要程序采取特殊的或显式的行动。

#### 6.3.2 存储器层次结构小结

**基于缓存的存储器层次结构行之有效，是因为较慢的存储设备比较快的储设备更便宜，还因为程序倾向于展示局部性**：

- **利用时间局部性**：由于时间局部性，同一数据对象可能会被多次使用。一且一个据对象在第一次不命中时被复制到缓存中，我们就会期望后面对该日标有一系列访间命中。因为缓存比低一层的存储设备更快，对后面的命中的服务会比最开始不命中快很多。
- **利用空间局部性**：块通常包含有多个数据对象。由于空间局部性，我们会期望后对该块中其他对象的访问能够补偿不命中后复制该块的花费。

![image-20230515113422076](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230515113422076.png)

### 6.4 高速缓存储存器

因为CPU与主存之间的发展差距逐渐增大，系统设计者开始在CPU寄存器文件和主存之间插入小的SRAM高速缓存存储器——**L1高速缓存(一级缓存)**。L1高速缓存的访问速度几乎和寄存器一样快，典型地是大约4个时钟周期。之后还插入了L2、L3高速缓存(向下在主存和CPU之间插入)，L2大约在10个时钟周期内访问到它，L3大约在50个时钟周期内访问到它。

![image-20230515115253030](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230515115253030.png)

#### 6.4.1 通用的高速缓存存储器组织结构

![image-20230521133252728](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230521133252728.png)高速缓存（S，E，B，m）的通用组织。a)高速缓存是一个高速缓存组的数组。每个组包含一个或多个行，每个行包含一个有效位，一些标记位，以及一个数据块；b)高速缓存的结构将m个地址位划分成了：t个标记位、s个组索引位和b个块偏移位。

![image-20230521133505479](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230521133505479.png)

当一条加载指令指示CPU从主存地址A中读一个字时，它将地址A发送到高速缓存。如果高速缓存正保存着地址A处那个字的副本，它就立即将那个字发回给CPU。那么高速缓存如何知道它是否包含地址A处那个字的副本的？**高速缓存的结构使得它能通过简单地检查地址位，找到所请求的字，类似于使用极其简单的哈希函数的哈希表。**

##### 高速缓存如何工作

参数S和B将m个地址位分为了三个字段——标记，组索引，块偏移。组索引，一个无符号整数标记这个字必须储存在哪个组中；标记中的t个标记位确定组内的第几行；当此行有效，且标记位与目标地址A的标记位匹配，则族中的这一行才包含这个字；确定目标A所在的行之后，通过b个块偏移位确定具体位置。

#### 6.4.2 直接映射高速缓存

每个组的高速缓存行数只有一行(E=1)的高速缓存被称为**直接映射高速缓存**。

<img src="https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230521135335138.png" alt="image-20230521135335138" style="zoom:80%;" />

CPU执行一条读内存字w的指令，向L1高速缓存请求这个字，如果L1中已经缓存这个字(有这个字的缓存副本)，则缓存命中，L1直接很快将其返回给CPU。如果L1中并未缓存w的副本，则缓存不命中，CPU需要等待L1从在主存中存储的将w抽取出并放在高速缓存中的一个行中，然后返回给CPU。

**高速缓存确定一个请求是否命中，然后抽取出被请求的字的过程分为三步：1）组选择；2）行匹配；3）字抽取。**

##### 组选择

高速缓存从w的地址中间抽取出s个组索引位。**这些位被解释成一个对应于一个组号的无符号整数。**如果把高速缓存看成是一个关于组的一维数组，那么这些组索引位就是一个到这个数组的索引。**图6-28展示了直接映射高速缓存的组选

<img src="https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230521140621957.png" alt="image-20230521140621957" style="zoom:80%;" />

##### 行匹配

已经选择了某个组，接下来的一步就**要确定是否有字w的一个副本存储在组包含的一个高速缓存行中。**在直接映射高速缓存中这很容易，而且很快，这是因为每个组只有一行。**当且仅当设置了有效位，而且高速缓存行中的标记与的地址中的标记相匹时，这一行中包含w的一个副本。**
图6-29展示了直接映射高速缓存中行匹配是如何工作的。在这个例子中，选中的组中只有一个高速缓存行。这个行的有效位设置了(标记和块中的位有意义)，因为这个高速缓存行中的标记位与地址中的标记位相匹配，所以我们知道我们想要的那个字的一个副本确实存储在这个行中，即得到一个缓存命中。另一方面，如果有效位没有置，或者标记不相匹配，那么我们就得到一个缓存不命中。

![image-20230521141216997](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230521141216997.png)

##### 字选择

确认w已经缓存在某行之后，需要确定所需的字在块中从哪里开始，此时**块偏移位提供了所需要的字的第一个字节的偏移。**就像把高速缓存看成一个行的数组一样，把块看成一个字节的数组，而字节偏移是到这个数组的一个索引。在这个示例中，块偏移位是100(2进制)，它表明w的副本是从块中的字节4开始的（假设字长为4字节）。

块偏移位的作用是将主存中的地址映射到缓存行中的位置。例如，如果缓存行的大小为64字节，则块偏移位需要使用6位二进制数来表示，因为64=2664=26。假设CPU要访问主存中的地址00x40123456，而缓存行的起始地址是0x40000000，则块偏移位可以通过下面的公式计算得到：

Offset=0x40123456 mod 64=0x16

这里，mod表示取模运算，Offset表示块偏移位的值，即数据在缓存行中的偏移量。因此，数据在缓存行中的地址是0x40000000+0x16=0x40000016。

**块偏移位的使用机制**：当CPU访问主存中的某个数据时，首先将主存地址分解为标记位、组索引和块偏移位三个部分。然后，根据组索引找到对应的缓存组，再在该缓存组中查找标记位与标记位相同的缓存行。如果找到了该缓存行，则根据块偏移位找到数据在缓存行中的位置，从而读取或写入数据。如果没有找到该缓存行，则需要从主存中读取该数据，并将其写入到对应的缓存行中。

假设CPU要访问主存中的地址0x40123456，而高速缓存的大小为8MB，采用直接映射方式，缓存行大小为64字节。则可以将主存地址分解为标记位、组索引和块偏移位三个部分，如下所示：

- **标记位：0x401234**
- **组索引：0x56 mod 2048=0x56**
- **块偏移位：0x40123456 mod 64=0x16**

根据组索引可以找到对应的缓存组，然后在该缓存组中查找标记位与标记位相同的缓存行。如果找到了该缓存行，则根据块偏移位找到数据在缓存行中的位置，从而读取或写入数据。如果没有找到该缓存行，则需要从主存中读取该数据，并将其写入到对应的缓存行中。

##### 缓存不命中时的行替换

**如果缓存不命中，那么它需要从存储器层次结构中的下一层取出被请求的块，然后将**
**新的块存储在组索引位指示的组中的一个高速缓存行中。**一般而言，如果组中都是有效高速缓存行了，那么必须要驱逐出一个现存的行。对于直接映射高速缓存来说，每个组只包含有一行，替换策略非常简单：**用新取出的行替换当前的行。**

##### 综合：运行中的直接映射高速缓存

假设有一个直接映射高速缓存，大小为4KB，采用固定大小为64字节的缓存行，主存大小为64KB。每个缓存行包含一个标记位、一个组索引和64字节的数据。缓存组数为64KB/64B=1024，组索引需要使用10位二进制数来表示。主存地址空间为0x0000−0xFFFF，每个地址对应一个字节，因此地址需要使用16位二进制数来表示。

现在，CPU要访问主存地址为0x1234的数据，以下是模拟缓存不命中的过程：

**根据主存地址计算组索引和块偏移位。**

- 组索引：0x1234 div 64=0x30
- 块偏移位：0x1234 mod 64=0x34

根据组索引找到对应的缓存组。

在缓存中查找组索引为0x30的缓存组，发现该组为空，即没有缓存行被映射到该组。因此，需要从主存中读取数据，并将其写入缓存组中。

**从主存中读取数据。**

根据主存地址0x1234，从主存中读取64字节的数据，包括0x1234到0x1273的16个字节。

**写入缓存行。**

将标记位设置为有效，组索引设置为0x30，并将从主存中读取的64字节数据写入缓存行中。

**从缓存中读取数据。**

根据组索引0x30和块偏移位0x34，在缓存组中查找对应的缓存行。发现该缓存行的标记位为有效，但是块偏移位为0x34的数据不存在于缓存行中。因此，需要从主存中读取该数据，并将其写入缓存行中。

##### 直接映射高速缓存中的冲突不命中

**当程序访问大小为2的幂的数组时，直接映射高速缓存中通常会发生冲突不命中。**因为直接映射高速缓存采用了固定大小的缓存行，每个缓存行包含一个标记位、一个组索引和若干个字节的数据。如果程序访问的数组大小为2的幂，例如32个字节、64个字节等，那么**这些数据往往会被映射到同一个缓存组中，从而导致冲突不命中。**

```c
//一个计算两个向量点积的函数
float dotpord(float x[8],floaty[8])
{
    float sum=0.0;
    int i;
    
    for(i=0;i<8;i++)
        sum+=x[i]*y[i];
    return sum;
}
```

**对于x和y来说，这个函数有良好的空间局部性，因此我们期望它的命中率会比较高。不过并不总是如此。**

<img src="https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230521152404294.png" alt="image-20230521152404294" style="zoom:80%;" />

在运行时，循环的第一次选代引用x[0]，缓存不命中会导致包含x[0]～x[3]的块被加载到组0。接下来是对y[0]的引用，又一次缓存不命中，导致包含y[0]～y[3]的块被复制到组0，覆盖前一次引用复制进来的x的值。在下一次选代中，对x[1]的引用不命
中，导致x[0]～x[3]的块被加载回组0，覆盖掉y[0]～y[3]的块。因而现在我们就有了一个冲突不命中，而且实际上后面每次对x和y的引用都会导致冲突不命中，因为我们在x和y的块之间**抖动（thrash）**。术语“抖动”描述的是这样一种情况，即**高速缓存反复地加载和驱逐相同的高速缓存块的组(只利用了一个组)。**

即使程序有良好的空间局部性，且高速缓存也有足够的空间来存放x[i]和y[i]的块，但是因为**这些块被映射到了同一个高速缓存组**，所以每次引用还是会导致冲突不命中。

**修正抖动**

缓存行抖动会降低高速缓存的效率，因为它会导致缓存不命中和缓存冲突。为了减少缓存行抖动，可以使用各种缓存优化技术，例如**缓存行填充**和**缓存预取**。

- **缓存行填充**是指在每个缓存行的末尾添加一些无用的数据，以确保不同的内存地址不会映射到同一个缓存行。
- **缓存预取**是指在访问内存地址之前预先加载相邻的内存地址到高速缓存中，以便在访问这些地址时可以最大限度地利用高速缓存。

在每个数组的结尾放B字节的填充，不是将x定义为`float x[8]`，而是定义成`float x[12]`，假设内存中y紧跟在x后面，则会产生下面的从数组元素到组的映射：

<img src="https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230521152427383.png" alt="image-20230521152427383" style="zoom:80%;" />

在x结尾添加了填充，x[i]和y[i]现在就映射到了不同的组，消除了抖动冲突不命中。

##### 使用中间的位作为索引

![image-20230521153119836](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230521153119836.png)

如果使用高位做索引，那么一些连续的内存块就会映射到相同的高速缓存块。例如，在图中，头四个块映射到第一个高速缓存组，第二个四个块映射到第二个组，依此类推。**如果一个程序有良好的空间局部性，顺序扫描一个数组的元素，那么在任何时刻，高速缓存都只保存着一个块大小的数组内容。这样对高速缓存的使用效率很低。**相比较而言，以中间位作为索引，相邻的块总是映射到不同的高速缓存行。在这里的情况中，高速缓存能够存放整个大小为C的数组片，这里C是高速缓存的大小。

#### 6.4.3 组相联高速缓存(一个组内合并多个直接映射高速缓存)

直接映射高速缓存中冲突不命中造成的问题，源于每个组只有一行(E=1)。**组相联高速缓存中每个组都保存有多于一个的高速缓存行(1<E<C/B)——E路组相联高速缓存。**

![image-20230521154100001](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230521154100001.png)

##### 组选择

它的组选择与直接映射高速缓存的组选择一样，组索引位标识组。

##### 行匹配&字选择

组相联高速缓存中的行匹配比直接映射高速缓存中的更复杂，因为它**必须检查多个行**
**的标记位和有效位，以确定所请求的字是否在集合中。**传统的内存是一个值的数组，以地址作为输入，并返回存储在那个地址的值。另一方面，相联存储器是一个（key，value）对的数组，以key为输入，返回与输入的key相匹配的（key，value）对中的value值。因此**可以把组相联高速缓存中的每个组都看成一个小的相联存储器，key是标记和有效位，而value就是块的内容。**

![image-20230521154404244](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230521154404244.png)

**组中的任何一行都可以包含任何映射到这个组的内存块。**所以高速缓存必须搜索组中的每一行，寻找一个有效的行，其标记与地址中的标记相匹配。如果高速缓存找到了这样一行，那么我们就命中，块偏移从这个块中选择一个字。

![image-20230521154929316](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230521154929316.png)

##### 缓存不命中时的行替换

如果CPU请求的字不在组的任何一行中，那么就是缓存不命中，高速缓存必须从内存中取出包含这个字的块。不过，一旦高速缓存取出了这个块，该替换哪个行呢？**如果有一个空行，那它就是个很好的候选。但是如果该组中没有空行，那么我们必须从中选择一个非空的行，则希望CPU不会很快引用这个被替换的行。**

**最简单的替换策略是随机选择要替换的行，其他更复杂的策略利用了局部性原理，以使在比较近的将来引用被替换的行的概率最小。**例如，最不常使用（Least-Frequently-Used，LFU）策略会替换在过去某个时间窗口内引用次数最少的那一行。最近最少使用（LeastRecently-Used，LRU）策略会替换最后一次访问时间最久远的那一行。所有这些策略都需要额外的时间和硬件。但是，越往存储器层次结构下面走，远离CPU，一次不命中的开销就会更加昂贵，用更好的替换策略使得不命中最少也变得更加值得了。

#### 6.4.4 全相联高速缓存(只有一个组，组内有多个行)

**全相联高速缓存是由一个包含所有高速缓存行的组(E=C/B)组成的。**

![image-20230521155925500](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230521155925500.png)

##### 组选择

**因为只有一个组，所以地址中没有组索引位，地址值被划分成了一个标记和一个块偏移。**

![image-20230521160024905](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230521160024905.png)

##### 行匹配和字选择

全相联高速缓存中的行匹配和字选择与组相联高速缓存中的是一样的，之间的区别主要是规模大小的问题。

![image-20230521160109227](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230521160109227.png)

因为高速缓存电路必须并行地搜索许多相匹配的标记，构造一个又大又快的相联高速缓存很困难，而且很昂贵。因此，全相联高速缓存只适合做小的高速缓存，例如虚拟内存系统中的翻译备用缓冲器（TLB）。

#### 6.4.5 有关写的问题

##### 读

**高速缓存关于读的操作非常简单。首先，在高速缓存中查找所需字w的副本。如果命中，立即返回字w给CPU。如果不命中，从存储器层次结构中较低层中取出包含字的块，将这个块存储到某个高速缓存行中（可能会驱逐一个有效的行），然后返回字w。**

##### 写

假设我们要写一个已经缓存了的字w（写命中，writehit）。**在高速缓存更新了它的w的副本之后，如何更新在层次结构中紧接着低一层中的副本？**

最简单的方法，称为**直写（write-through）**，就是<u>**立即**将w的高速缓存块写回到紧接着的低一层中。虽然简单，但是直写的缺点是每次写都会引起总线流量。</u>

另一种方法，称为**写回（write-back）**，<u>尽可能地**推退更新**，只有当替换算法要驱逐这个更新过的块时，才把它写到紧接着的低一层中。（减少写的次数）</u>

**由于局部性，写回能显著地减少总线流量，但是它的缺点是增加了复杂性。高速缓存必须为每个高速缓存行维护一个额外的修改位（dirtybit），表明这个高速缓存块是否被修改过。**

##### 处理写不命中 

一种方法，称为**写分配（write-allocate）**，加载相应的低一层中的块到高速缓存中，然后更新这个高速缓存块。写分配试图利用写的空间局部性，但是缺点是每次不命中都会导致一个块从低一层传送到高速缓存。

另一种方法，称为**非写分配（notwrite-allocate）**，避开高速缓存，直接把这个字写到低一层中。

**直写高速缓存通常是非写分配的。写回高速缓存通常是写分配的。**

建议在心里采用**一个使用写回和写分配的高速缓存的模型**。这样建议有几个原因，通常，**由于较长的传送时间，存储器层次结构中较低层的缓存更可能使用写回，而不是直写。**例如，虚拟内存系统（用主存作为存储在磁盘上的块的缓存）只使用写回。但是由于逻辑电路密度的提高，写回的高复杂性也越来越不成为阻碍了，我们在现代系统的所有层次上都能看到写回缓存。所以这种假设符合当前的趋势。假设使用写回写分配方法的另一个原因是，**它与处理读的方式相对称，因为写回写分配试图利用局部性**。因此，我们可以在高层次上开发我们的程序，展示良好的空间和时间局部性，而不是试图为某一个存储器系统进行优化。

#### 6.4.6 一个真实的高速缓存层次结构的剖析

到目前为止，我们一直假设高速缓存只保存程序数据。不过，实际上，**高速缓存既保**
**存数据，也保存指令。**

**只保存指令的高速缓存称为i-cache。只保存程序数据的高速缓存称为d-cache。既保存指令又包括数据的高速缓存称为统一的高速缓存（unified cache）。**

现代处理器包括独立的i-cache和d-cache。这样做有很多原因。**有两个独立的高速缓存，处理器能够同时读一个指令字和一个数据字。**i-cache通常是只读的，因此比较简单。通常会针对不同的访问模式来优化这两个高速缓存，它们可以有不同的块大小，相联度和容量。使用不同的高速缓存也确保了数据访问不会与指令访问形成冲突不命中，反过来也是一样，代价就是可能会引起容量不命中增加。

图6-38给出了Intel Core i7处理器的高速缓存层次结构。**每个CPU芯片有四个核。每个核有自己私有的L1 i-cache、L1 d-cache和L2统一的高速缓存。所有的核共享片上L3统一的高速缓存。**这个层次结构的一个有趣的特性是所有的SRAM高速缓存存储器都在CPU芯片上。

<img src="https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230523203136100.png" alt="image-20230523203136100" style="zoom:80%;" />

![image-20230523203352811](https://gitee.com/zhengzhivon/images/raw/master/imgs/image-20230523203352811.png)

#### 6.4.7 高速缓存参数的性能影响

